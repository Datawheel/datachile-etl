{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>MAIN CODE</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store', 'data_temp', 'dropout_rate.ipynb', '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/mauricio/datachile-etl/childhood/dropout_rate\")\n",
    "os.getcwd()\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      commune_code value  year  status education\n",
      "8342       12401.0     4  2017       3       NaN\n",
      "8343       12402.0     1  2017       3       NaN\n",
      "8344       13101.0   686  2017       3       NaN\n",
      "8345       13102.0    80  2017       3       NaN\n",
      "8346       13103.0   152  2017       3       NaN\n",
      "8347       13104.0   196  2017       3       NaN\n",
      "8348       13105.0   196  2017       3       NaN\n",
      "8349       13106.0   234  2017       3       NaN\n",
      "8350       13107.0    91  2017       3       NaN\n",
      "8351       13108.0   307  2017       3       NaN\n",
      "8352       13109.0   150  2017       3       NaN\n",
      "8353       13110.0   396  2017       3       NaN\n",
      "8354       13111.0   125  2017       3       NaN\n",
      "8355       13112.0   295  2017       3       NaN\n",
      "8356       13113.0   113  2017       3       NaN\n",
      "8357       13114.0   155  2017       3       NaN\n",
      "8358       13115.0    61  2017       3       NaN\n",
      "8359       13116.0    70  2017       3       NaN\n",
      "8360       13117.0    87  2017       3       NaN\n",
      "8361       13118.0   129  2017       3       NaN\n",
      "8362       13119.0   446  2017       3       NaN\n",
      "8363       13120.0   171  2017       3       NaN\n",
      "8364       13121.0    84  2017       3       NaN\n",
      "8365       13122.0   293  2017       3       NaN\n",
      "8366       13123.0   151  2017       3       NaN\n",
      "8367       13124.0   173  2017       3       NaN\n",
      "8368       13125.0   264  2017       3       NaN\n",
      "8369       13126.0   172  2017       3       NaN\n",
      "8370       13127.0   272  2017       3       NaN\n",
      "8371       13128.0   246  2017       3       NaN\n",
      "8372       13129.0    86  2017       3       NaN\n",
      "8373       13130.0   109  2017       3       NaN\n",
      "8374       13131.0   136  2017       3       NaN\n",
      "8375       13132.0    87  2017       3       NaN\n",
      "8376       13201.0   591  2017       3       NaN\n",
      "8377       13202.0    11  2017       3       NaN\n",
      "8378       13203.0    14  2017       3       NaN\n",
      "8379       13301.0   224  2017       3       NaN\n",
      "8380       13302.0   120  2017       3       NaN\n",
      "8381       13303.0    18  2017       3       NaN\n",
      "8382       13401.0   317  2017       3       NaN\n",
      "8383       13402.0    68  2017       3       NaN\n",
      "8384       13403.0    13  2017       3       NaN\n",
      "8385       13404.0    52  2017       3       NaN\n",
      "8386       13501.0    95  2017       3       NaN\n",
      "8387       13502.0     2  2017       3       NaN\n",
      "8388       13503.0    14  2017       3       NaN\n",
      "8389       13504.0     1  2017       3       NaN\n",
      "8390       13505.0     9  2017       3       NaN\n",
      "8391       13601.0    80  2017       3       NaN\n",
      "8392       13602.0    21  2017       3       NaN\n",
      "8393       13603.0    28  2017       3       NaN\n",
      "8394       13604.0    93  2017       3       NaN\n",
      "8395       13605.0    55  2017       3       NaN\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# declares timer, locks absolute_path to working directory, declares file URLs and list of df\n",
    "before = time.perf_counter()\n",
    "absolute_path = os.getcwd()\n",
    "urls = [\"http://www.creciendoconderechos.gob.cl/docs/Rendimiento_Escolar_Basica.xlsx\", \"http://www.creciendoconderechos.gob.cl/docs/Rendimiento_Escolar_Media.xlsx\"]\n",
    "df_list = []\n",
    "\n",
    "# creates data_temp folder and changes working directory\n",
    "if os.path.isdir(\"data_temp\") == False:\n",
    "    os.mkdir(\"data_temp\")    \n",
    "os.chdir(\"data_temp\")\n",
    "\n",
    "# generates header row\n",
    "hrow = [\"region_code\", \"region_name\", \"province_code\", \"province_name\", \"commune_code\", \"commune_name\"]\n",
    "for yr in range(2010,2018):\n",
    "    hrow.append(\"total_\"+str(yr))\n",
    "    hrow.append(\"prom_num_\"+str(yr))\n",
    "    hrow.append(\"prom_perc_\"+str(yr))\n",
    "    hrow.append(\"rep_num_\"+str(yr))\n",
    "    hrow.append(\"rep_perc_\"+str(yr))\n",
    "    hrow.append(\"drop_num_\"+str(yr))\n",
    "    hrow.append(\"drop_perc_\"+str(yr))\n",
    "\n",
    "# processing\n",
    "df = pd.read_excel(\"Rendimiento_Escolar_Basica.xlsx\", header = None, sheet_name = \"Informaci√≥n Base Comunal\", skiprows = list(range(5)))\n",
    "df.columns = hrow\n",
    "#df[hrow[:6]] = df[hrow[:6]].fillna(method = \"ffill\")\n",
    "\n",
    "# selects necessary columns\n",
    "sel_cols = [\"commune_code\"]\n",
    "for yr in range(2010,2018):\n",
    "    sel_cols.append(\"prom_num_\"+str(yr))\n",
    "    sel_cols.append(\"rep_num_\"+str(yr))\n",
    "    sel_cols.append(\"drop_num_\"+str(yr))\n",
    "    \n",
    "df = df[sel_cols]\n",
    "\n",
    "# melts columns to make dataframe tidy\n",
    "melt_cols = [col for col in df.columns if col != \"commune_code\"]\n",
    "df = pd.melt(df, id_vars = \"commune_code\", value_vars = melt_cols, var_name = \"status_year\", value_name = \"value\")\n",
    "\n",
    "# creates year column\n",
    "def get_year(row, col):\n",
    "    target = row[col]\n",
    "    reg = re.search(\"\\d\", target)\n",
    "    first = reg.start()\n",
    "    y = target[first : first + 4]\n",
    "    return y\n",
    "\n",
    "df[\"year\"] = df.apply(get_year, col = \"status_year\", axis = 1)\n",
    "\n",
    "# creates status column\n",
    "def get_status(row, col):\n",
    "    stat = {\"prom\": 1, \"rep\": 2, \"drop\": 3}\n",
    "    return next((stat[k] for k in stat.keys() if k in row[col]), np.nan)\n",
    "\n",
    "df[\"status\"] = df.apply(get_status, col = \"status_year\", axis = 1)\n",
    "\n",
    "# drops status_year column and NaN rows on commune_id\n",
    "df = df[[c for c in df.columns if c != \"status_year\"]]\n",
    "df = df.dropna(subset = [\"commune_code\"])\n",
    "\n",
    "# creates education column\n",
    "ed = re.search(\"_(.+?)_(.+?).xlsx\", urls[0])\n",
    "ed = ed.group(2)\n",
    "df[\"education\"] = pd.Series([ed] * df.shape[0])\n",
    "\n",
    "print(df.iloc[8250:,:])\n",
    "\n",
    "# comes back to original path\n",
    "os.chdir(absolute_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>IVE JUNAEB Code</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import urllib3\n",
    "\n",
    "# declares timer and locks absolute path to working directory\n",
    "before = time.perf_counter()\n",
    "absolute_path = os.getcwd()\n",
    "\n",
    "# solves SSL certificate issues error when retrieving files \n",
    "#import os, ssl\n",
    "#if (not os.environ.get(\"PYTHONHTTPSVERIFY\", \"\") and getattr(ssl, \"_create_unverified_context\", None)): \n",
    "#    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# Solving SSL certificate issue\n",
    "#urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# retrieve links from site\n",
    "url = \"https://www.junaeb.cl/ive\"\n",
    "page = requests.get(url, verify = False)\n",
    "soup = BeautifulSoup(page.text, \"lxml\")\n",
    "a_tags = soup.find_all('a')\n",
    "all_links = [link.get('href') for link in a_tags]\n",
    "links = []\n",
    "for link in all_links:\n",
    "    if \".xls\" in link and \"IVESINAE_COMUNA_2013\" not in link:\n",
    "        links.append(link)\n",
    "        \n",
    "years_df = []\n",
    "\n",
    "# creates data_temp folder and changes working directory\n",
    "if os.path.isdir(\"data_temp\") == False:\n",
    "    os.mkdir(\"data_temp\")    \n",
    "os.chdir(\"data_temp\")\n",
    "\n",
    "# downloads files\n",
    "for url in links:\n",
    "    encoded_url = urllib.parse.quote(url.encode('utf-8'),':/')\n",
    "    filename = encoded_url[encoded_url.rfind(\"/\")+1:]\n",
    "    if filename not in os.listdir():\n",
    "        urllib.request.urlretrieve(encoded_url, filename)\n",
    "        print(\"{:.2f} s | Downloaded {}\".format(time.perf_counter()-before, url))\n",
    "\n",
    "# processing function\n",
    "def clean(file, year):\n",
    "    \n",
    "    #defines scope of variable\n",
    "    global years_df\n",
    "        \n",
    "    # reads Excel file and defines available sheets on file\n",
    "    df = pd.read_excel(file, sheet_name = None, encoding=\"utf-8\")\n",
    "    sheets_list = list(df.keys())\n",
    "    sheets = sheets_list[:2]\n",
    "\n",
    "    for tb in sheets:\n",
    "        # deletes last two columns and last row\n",
    "        df[tb] = df[tb].drop(df[tb].columns[14:], axis=1)\n",
    "        last_row = df[tb].shape[0]\n",
    "        df[tb] = df[tb].drop(last_row-1)\n",
    "\n",
    "        # fills NaN with 0\n",
    "        df[tb].iloc[:, 9:] = df[tb].iloc[:, 9:].fillna(0)\n",
    "\n",
    "        # creates new column to make dataframe tidy\n",
    "        tb_col = tb.replace(\"√Å\",\"A\")\n",
    "        df[tb][\"level\"] = pd.Series([tb_col] * df[tb].shape[0])\n",
    "            \n",
    "        # creates new year column\n",
    "        df[tb][\"year\"] = pd.Series([year] * df[tb].shape[0])\n",
    "\n",
    "        # melts dataframe to make it tidy\n",
    "        priorities = df[tb].columns[9:14]\n",
    "        df[tb] = pd.melt(df[tb], id_vars = [x for x in df[tb].columns if x not in priorities], value_vars = priorities, var_name = \"priority\", value_name = \"total\")\n",
    "\n",
    "        # changes column names\n",
    "        df[tb].columns = [\"rbd\", \"dv_rbd\", \"school_name\", \"dependency\", \"area\", \"region_code\", \"province_code\", \"commune_code\", \"commune_name\", \"level\", \"year\", \"priority\", \"total\"]\n",
    "        \n",
    "        # drops unnecesary columns: \"dv_rbd\", \"school_name\", \"region_code\", \"province_code\" and \"commune_name\"\n",
    "        df[tb] = df[tb][[\"rbd\", \"dependency\", \"area\", \"commune_code\", \"level\", \"year\", \"priority\", \"total\"]]\n",
    "        \n",
    "        # changes column types\n",
    "        num_cols = [\"rbd\", \"commune_code\", \"total\"]\n",
    "        df[tb][num_cols] = df[tb][num_cols].apply(pd.to_numeric, downcast=\"integer\")\n",
    "        \n",
    "        # changes string columns to uppercase\n",
    "        def uppercase(row, col):\n",
    "            return row[col].upper()\n",
    "        \n",
    "        str_cols = [x for x in df[tb].columns if x not in num_cols]\n",
    "        \n",
    "        for column in str_cols:\n",
    "            df[tb][column] = df[tb].apply(uppercase, col = column, axis = 1) \n",
    "         \n",
    "    # concatenates both dataframes\n",
    "    df = pd.concat([df[sheets[0]], df[sheets[1]]], ignore_index=True)\n",
    "    years_df.append(df)\n",
    "\n",
    "# function to get year information\n",
    "def get_year(string):\n",
    "    reg = re.search(\"\\d\", string)\n",
    "    first = reg.start()\n",
    "    y = string[first : first + 4]\n",
    "    return y \n",
    "\n",
    "# processes each link\n",
    "for file in os.listdir():\n",
    "    new_filename = file[file.rfind(\"/\") + 1:]\n",
    "    print(\"{:.2f} s | Cleaning {}\".format(time.perf_counter()-before, new_filename))\n",
    "    clean(new_filename, get_year(new_filename))\n",
    "\n",
    "# concatenates each year's dataframe\n",
    "df = pd.concat(years_df, ignore_index=True)\n",
    "print(\"{:.2f} s | Concatenated each year's dataframe.\".format(time.perf_counter()-before))\n",
    "\n",
    "# classifies dependencies: administration\n",
    "def classify_dependencies(row, col):\n",
    "    dep_dict = {\"SUB\": 3, \"CORP\": 1, \"MUNI\": 2, \"DELE\": 5}\n",
    "    return next((dep_dict[k] for k in dep_dict.keys() if k in row[col]), np.nan)\n",
    "    \n",
    "df[\"dependency\"] = df.apply(classify_dependencies, col = \"dependency\", axis = 1)\n",
    "df = df.rename(columns = {\"dependency\":\"administration\"})\n",
    "print(\"{:.2f} s | Classified administration column.\".format(time.perf_counter()-before))\n",
    "\n",
    "# Changes IDs and column names (area: zone)\n",
    "def zone(row, col):\n",
    "    zone_dict = {\"URBANO\": 1, \"RURAL\": 2}\n",
    "    return next((zone_dict[k] for k in zone_dict.keys() if k in row[col]), np.nan)\n",
    "    \n",
    "df[\"area\"] = df.apply(zone, col = \"area\", axis = 1)\n",
    "df = df.rename(columns = {\"area\":\"zone_id\"})\n",
    "print(\"{:.2f} s | Changed zone IDs.\".format(time.perf_counter()-before))\n",
    "\n",
    "# classifies priorities\n",
    "def classify_priorities(row, col):\n",
    "    pri_dict = {\"SIN INFORMACION\": 0, \"SIN INFORMACI√ìN\": 0, \"PRIMERA PRIORIDAD\": 1, \"1¬™ PRIORIDAD\": 1, \"SEGUNDA PRIORIDAD\": 2, \"2¬™ PRIORIDAD\": 2, \"TERCERA PRIORIDAD\": 3, \"3¬™ PRIORIDAD\": 3, \"NO VULNERABLES\": 4, \"NO APLICA\": 4}\n",
    "    return pri_dict[row[col]]\n",
    "    \n",
    "df[\"priority\"] = df.apply(classify_priorities, col = \"priority\", axis = 1)\n",
    "df[\"priority\"] = pd.to_numeric(df[\"priority\"], downcast = \"integer\")\n",
    "print(\"{:.2f} s | Classified priority column.\".format(time.perf_counter()-before))\n",
    "\n",
    "# Changes IDs and column names (level: education)\n",
    "def education(row, col):\n",
    "    ed_dict = {\"BASICA\": 1, \"MEDIA\": 2}\n",
    "    return next((ed_dict[k] for k in ed_dict.keys() if k in row[col]), np.nan)\n",
    "    \n",
    "df[\"level\"] = df.apply(education, col = \"level\", axis = 1)\n",
    "df = df.rename(columns = {\"level\":\"education\"})\n",
    "print(\"{:.2f} s | Changed education IDs.\".format(time.perf_counter()-before))\n",
    "\n",
    "# writes datachile official IDs for each commune and drops columns: dv_rbd and school_name\n",
    "df_ids = pd.read_csv(\"https://raw.githubusercontent.com/datachile/datachile-etl/master/official_ids/2017_06_27_comunas_datachile_fixed.csv\")\n",
    "df = pd.merge(df, df_ids, left_on = \"commune_code\", right_on = \"comuna_customs_id\")\n",
    "df = df[[\"rbd\", \"administration\", \"zone_id\", \"comuna_datachile_id\", \"education\", \"year\", \"priority\", \"total\"]]\n",
    "df = df.rename(columns = {\"administration\": \"administration_id\", \"comuna_datachile_id\": \"comuna_id\", \"education\": \"education_id\", \"priority\": \"priority_id\"})\n",
    "\n",
    "# comes back to original path, creates data_final folder and exports as csv\n",
    "os.chdir(absolute_path)\n",
    "if os.path.isdir(\"data_final\") == False:\n",
    "    os.mkdir(\"data_final\")    \n",
    "os.chdir(\"data_final\")\n",
    "df.to_csv(\"ive_junaeb.csv\", index = False)\n",
    "print(\"{:.2f} s | Exported CSV file.\".format(time.perf_counter()-before))\n",
    "\n",
    "# creates CSV with priority IDs\n",
    "pri_tb = {\"id\": list(range(5)), \"name_es\": [\"Sin informaci√≥n\", \"Primera prioridad\", \"Segunda prioridad\", \"Tercera prioridad\", \"No vulnerables\"], \"name_en\": [\"No information\", \"First priority\", \"Second priority\", \"Third priority\", \"Not vulnerable\"]}\n",
    "pri_df = pd.DataFrame(pri_tb)\n",
    "pri_df.to_csv(\"priority.csv\", index = False)\n",
    "print(\"{:.2f} s | Exported priority.csv\".format(time.perf_counter()-before))\n",
    "\n",
    "# comes back to original path\n",
    "os.chdir(absolute_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
